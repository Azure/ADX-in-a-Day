.create table logsRaw(
    Timestamp:datetime, 
    Source:string, 
    Node:string, 
    Level:string, 
    Component:string, 
    ClientRequestId:string, 
    Message:string, 
    Properties:dynamic
) 

logsRaw
| count

SELECT COUNT() FROM logsRaw

explain SELECT MAX(Timestamp) AS MaxTimestamp FROM logsRaw WHERE Level='Error'

logsRaw
| where Level == "Error"
| summarize max(Timestamp)


logsRaw
| where Level=="Error"
| take 10


logsRaw
| summarize count() // or: count

logsRaw
| summarize avg(Timestamp), max(Timestamp)


logsRaw
| where Properties <>''
| take 10


logsRaw
| where Component == "DOWNLOADER"
| take 100
| extend originalSize=tolong(Properties.OriginalSize), compressedSize=tolong(Properties.compressedSize), toguid(ClientRequestId)
| getschema 


logsRaw
| project Timestamp, ClientRequestId, Level
| where Timestamp >= datetime(2014-03-08 01:00) and Timestamp <= datetime(2014-03-08 10:00)
| count


logsRaw
| where Component =='INGESTOR_EXECUTER'
| count

logsRaw
| summarize count() by Component
| sort by count_ 


// As part of the incident investigation, you want to extract format and rowCount from INGESTOR_EXECUTER [sic] component.
// Rename the calculated fields to fileFormat and rowCount respectively. 
// Also, Make Sure Timestamp, fileFormat and rowCount are the first 3 columns.

logsRaw
| where Component =='INGESTOR_EXECUTER'
| project Timestamp, Properties.size, fileFormat=tostring(Properties.format), rowCount=Properties.rowCount
| summarize count() by fileFormat
| render piechart 
// | distinct fileFormat

logsRaw
| where Component =='DATAACCESS'
| count

logsRaw
| where Message contains "ingestion"
| summarize count() by Level


logsRaw
| summarize count() by Level
| render piechart 


logsRaw
| where Timestamp >= datetime(2014-03-08 09:50) and Timestamp <= datetime(2014-03-08 10:00)
| summarize count() by bin(Timestamp,1ms)
| render timechart 


.create function ManiputatelogsRaw() {
logsRaw
| where Component in (
  'INGESTOR_EXECUTER', 
  'INGESTOR_GATEWAY', 
  'INTEGRATIONDATABASE',
  'INTEGRATIONSERVICEFLOWS', 
  'INTEGRATIONSERVICETRACE', 
  'DOWNLOADER')
}


.create table ingestionLogs (
  Timestamp: datetime, 
  Source: string,
  Node: string, 
  Level: string, 
  Component: string, 
  ClientRequestId: string, 
  Message: string, 
  Properties: dynamic)


.alter table ingestionLogs policy update @'[{ "IsEnabled": true, "Source": "logsRaw", "Query": "ManiputatelogsRaw()", "IsTransactional": true, "PropagateIngestionProperties": false}]'


.show tables details 

.show table ingestionLogs policy update   


// Note: execute the below commands one after another => Using operationId(output of each command), 
//check the status and execute a new command only after the previous one is completed

.show operations 

.show journal 

.show commands-and-queries 

// in-query ingest as a single script
.execute database script <|
.ingest into table logsRaw (h'https://logsbenchmark00.blob.core.windows.net/logsbenchmark-onegb/2014/03/08/00/data.csv.gz?sp=rl&st=2022-08-18T00:00:00Z&se=2030-01-01T00:00:00Z&spr=https&sv=2021-06-08&sr=c&sig=5pjOow5An3%2BTs5mZ%2FyosJBPtDvV7%2FXfDO8pLEeeylVc%3D') with (format='csv', creationTime='2014-03-08T00:00:00Z');
.ingest async into table logsRaw (h'https://logsbenchmark00.blob.core.windows.net/logsbenchmark-onegb/2014/03/08/01/data.csv.gz?sp=rl&st=2022-08-18T00:00:00Z&se=2030-01-01T00:00:00Z&spr=https&sv=2021-06-08&sr=c&sig=5pjOow5An3%2BTs5mZ%2FyosJBPtDvV7%2FXfDO8pLEeeylVc%3D') with (format='csv', creationTime='2014-03-08T01:00:00Z');
.ingest async into table logsRaw (h'https://logsbenchmark00.blob.core.windows.net/logsbenchmark-onegb/2014/03/08/02/data.csv.gz?sp=rl&st=2022-08-18T00:00:00Z&se=2030-01-01T00:00:00Z&spr=https&sv=2021-06-08&sr=c&sig=5pjOow5An3%2BTs5mZ%2FyosJBPtDvV7%2FXfDO8pLEeeylVc%3D') with (format='csv', creationTime='2014-03-08T02:00:00Z');
.ingest async into table logsRaw (h'https://logsbenchmark00.blob.core.windows.net/logsbenchmark-onegb/2014/03/08/03/data.csv.gz?sp=rl&st=2022-08-18T00:00:00Z&se=2030-01-01T00:00:00Z&spr=https&sv=2021-06-08&sr=c&sig=5pjOow5An3%2BTs5mZ%2FyosJBPtDvV7%2FXfDO8pLEeeylVc%3D') with (format='csv', creationTime='2014-03-08T03:00:00Z');
.ingest async into table logsRaw (h'https://logsbenchmark00.blob.core.windows.net/logsbenchmark-onegb/2014/03/08/04/data.csv.gz?sp=rl&st=2022-08-18T00:00:00Z&se=2030-01-01T00:00:00Z&spr=https&sv=2021-06-08&sr=c&sig=5pjOow5An3%2BTs5mZ%2FyosJBPtDvV7%2FXfDO8pLEeeylVc%3D') with (format='csv', creationTime='2014-03-08T04:00:00Z');

.show operations 
| where OperationId == 'f265ff45-bb4a-4ab1-90c7-16ff0aaefdba' 

ingestionLogs
| count

ingestionLogs count / logsRaw count

ingestionLogs
| count //93648

logsRaw
| where ingestion_time() >= ago(1h)
| count //1442786

print ratio=todouble(93648)/todouble(1442786)
// do you want a easier...programatic way? then proceed.


// using expressions & multi-line statements
let x=toscalar(ingestionLogs | count);
let y=toscalar(logsRaw | where ingestion_time() >= ago(1h) | count);
print ratio=todouble(x)/todouble(y)

// same command all in-one line without using variables, but hard to follow.
print ratio=todouble(toscalar(ingestionLogs | count))/todouble(logsRaw | where ingestion_time() >= ago(1h) | count)

// using join full cross-join & multi-line statements
let x=ingestionLogs
| count
| extend y=1;
logsRaw
| where ingestion_time() >= ago(1h)
| count
| extend y=1
| join kind=leftouter x on $left.y==$right.y
| extend ratio=todouble(Count1)/todouble(Count)
